services:
  # ======================
  # Hadoop HDFS + YARN
  # ======================
  namenode:
    image: bde2020/hadoop-namenode:latest
    container_name: namenode
    environment:
      - CLUSTER_NAME=lab-cluster
      - CORE_CONF_fs_defaultFS=hdfs://namenode:8020
      - HDFS_CONF_dfs_replication=2
    ports:
      - "9870:9870"   # Web UI NameNode
      - "8020:8020"   # RPC NameNode
    volumes:
      - namenode-data:/hadoop/dfs/name
    networks:
      - bigdata

  datanode1:
    image: bde2020/hadoop-datanode:latest
    container_name: datanode1
    environment:
      - CORE_CONF_fs_defaultFS=hdfs://namenode:8020
      - HDFS_CONF_dfs_replication=2
    ports:
      - "9864:9864"   # Web UI DataNode 1
    volumes:
      - datanode1-data:/hadoop/dfs/data
    depends_on:
      - namenode
    networks:
      - bigdata

  datanode2:
    image: bde2020/hadoop-datanode:latest
    container_name: datanode2
    environment:
      - CORE_CONF_fs_defaultFS=hdfs://namenode:8020
      - HDFS_CONF_dfs_replication=2
    ports:
      - "9865:9864"   # map port khác ngoài host
    volumes:
      - datanode2-data:/hadoop/dfs/data
    depends_on:
      - namenode
    networks:
      - bigdata

  resourcemanager:
    image: bde2020/hadoop-resourcemanager:latest
    container_name: resourcemanager
    environment:
      - CORE_CONF_fs_defaultFS=hdfs://namenode:8020
      - YARN_CONF_yarn_resourcemanager_hostname=resourcemanager
    ports:
      - "8088:8088"   # YARN ResourceManager UI
    depends_on:
      - namenode
    networks:
      - bigdata

  nodemanager1:
    image: bde2020/hadoop-nodemanager:latest
    container_name: nodemanager1
    environment:
      - CORE_CONF_fs_defaultFS=hdfs://namenode:8020
      - YARN_CONF_yarn_resourcemanager_hostname=resourcemanager
    depends_on:
      - resourcemanager
    networks:
      - bigdata

  nodemanager2:
    image: bde2020/hadoop-nodemanager:latest
    container_name: nodemanager2
    environment:
      - CORE_CONF_fs_defaultFS=hdfs://namenode:8020
      - YARN_CONF_yarn_resourcemanager_hostname=resourcemanager
    depends_on:
      - resourcemanager
    networks:
      - bigdata

  historyserver:
    image: bde2020/hadoop-historyserver:latest
    container_name: historyserver
    environment:
      - CORE_CONF_fs_defaultFS=hdfs://namenode:8020
    ports:
      - "8188:8188"   # Job History UI
    depends_on:
      - namenode
    networks:
      - bigdata

  # ======================
  # Spark (Standalone)
  # ======================
  spark-master:
    image: bde2020/spark-master:3.3.0-hadoop3.3
    container_name: spark-master
    environment:
      - INIT_DAEMON_STEP=setup_spark
    ports:
      - "8080:8080"   # Spark Master UI
      - "7077:7077"   # Spark Master Port
    depends_on:
      - namenode
    networks:
      - bigdata

  spark-worker-1:
    image: bde2020/spark-worker:3.3.0-hadoop3.3
    container_name: spark-worker-1
    environment:
      - SPARK_MASTER=spark://spark-master:7077
    depends_on:
      - spark-master
    networks:
      - bigdata

  # ======================
  # Kafka + Zookeeper
  # ======================
  zookeeper:
    image: zookeeper:3.9   # hoặc chỉ "zookeeper" cũng được
    container_name: zookeeper
    restart: always
    ports:
      - "2181:2181"
    networks:
      - bigdata

  kafka:
    image: confluentinc/cp-kafka:7.5.0
    container_name: kafka
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
    networks:
      - bigdata


volumes:
  namenode-data:
  datanode1-data:
  datanode2-data:

networks:
  bigdata:
    driver: bridge
