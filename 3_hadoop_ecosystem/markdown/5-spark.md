---
time: 11/04/2022
title: N·ªÅn t·∫£ng x·ª≠ l√Ω d·ªØ li·ªáu l·ªõn Apache Spark
description: Apache Spark l√† n·ªÅn t·∫£ng x·ª≠ l√Ω d·ªØ li·ªáu l·ªõn in-memory ƒë∆∞·ª£c thi·∫øt k·∫ø cho hi·ªáu nƒÉng cao v√† kh·∫£ nƒÉng x·ª≠ l√Ω linh ho·∫°t. Kh√°c v·ªõi MapReduce ch·ªâ ho·∫°t ƒë·ªông theo m√¥ h√¨nh batch, Spark gi·ªØ d·ªØ li·ªáu trong b·ªô nh·ªõ qua nhi·ªÅu b∆∞·ªõc t√≠nh to√°n, gi√∫p tƒÉng t·ªëc ƒë√°ng k·ªÉ c√°c t√°c v·ª• l·∫∑p nh∆∞ h·ªçc m√°y, ph√¢n t√≠ch bi·ªÉu ƒë·ªì v√† x·ª≠ l√Ω t∆∞∆°ng t√°c. Nh·ªù kh·∫£ nƒÉng m·ªü r·ªông v√† t·ªëc ƒë·ªô v∆∞·ª£t tr·ªôi, Spark tr·ªü th√†nh l·ª±a ch·ªçn ph·ªï bi·∫øn trong c√°c h·ªá th·ªëng ph√¢n t√≠ch d·ªØ li·ªáu hi·ªán ƒë·∫°i.
banner_url: https://raw.githubusercontent.com/MinhHuuNguyen/data-engineer-lectures/refs/heads/master/3_hadoop_ecosystem/images/5-spark/banner.jpeg
tags: [big-data, hadoop]
is_highlight: false
is_published: true
---

## 1. Gi·ªõi thi·ªáu chung v·ªÅ Spark

Apache Spark l√† m·ªôt h·ªá th·ªëng x·ª≠ l√Ω ph√¢n t√°n m√£ ngu·ªìn m·ªü ƒë∆∞·ª£c thi·∫øt k·∫ø cho c√°c b√†i to√°n d·ªØ li·ªáu l·ªõn ƒë∆∞·ª£c ph√°t tri·ªÉn b·ªüi Apache Software Foundation.

Spark h·ªó tr·ª£ ƒëa ng√¥n ng·ªØ l·∫≠p tr√¨nh (Java, Scala, Python, R) v√† nhi·ªÅu lo·∫°i workload nh∆∞ x·ª≠ l√Ω theo l√¥ (batch-based), x·ª≠ l√Ω theo th·ªùi gian th·ª±c (streaming), h·ªçc m√°y (machine learning) v√† x·ª≠ l√Ω ƒë·ªì th·ªã (graph processing), truy v·∫•n SQL ...

ƒêi·ªÉm n·ªïi b·∫≠t c·ªßa Spark l√† th·ª±c thi t√≠nh to√°n trong b·ªô nh·ªõ (in-memory) k·∫øt h·ª£p v·ªõi t·ªëi ∆∞u h√≥a truy v·∫•n, gi√∫p x·ª≠ l√Ω d·ªØ li·ªáu nhanh h∆°n nhi·ªÅu so v·ªõi m√¥ h√¨nh MapReduce truy·ªÅn th·ªëng.
Do v·∫≠y, Spark ƒë√£ tr·ªü th√†nh c√¥ng c·ª• quan tr·ªçng trong h·ªá sinh th√°i x·ª≠ l√Ω d·ªØ li·ªáu ph√¢n t√°n hi·ªán ƒë·∫°i.

<img src="https://raw.githubusercontent.com/MinhHuuNguyen/data-engineer-lectures/refs/heads/master/3_hadoop_ecosystem/images/5-spark/in_memory.jpeg" style="width: 800px;"/>

Spark c√≥ th·ªÉ ch·∫°y tr√™n nhi·ªÅu h·ªá th·ªëng qu·∫£n l√Ω c·ª•m kh√°c nhau (cluster manager) nh∆∞ Hadoop YARN, Apache Mesos ho·∫∑c Spark Standalone Scheduler.
Spark c≈©ng t√≠ch h·ª£p t·ªët v·ªõi HDFS v√† c√°c ngu·ªìn l∆∞u tr·ªØ ph√¢n t√°n kh√°c.

## 2. Ki·∫øn tr√∫c chung c·ªßa Spark

### 2.1. C√°c th√†nh ph·∫ßn trong Spark

C√°c th√†nh ph·∫ßn trong Spark g·ªìm:
- **Spark Core (API + Execution Engine):** l√µi cung c·∫•p API c∆° b·∫£n v√† engine th·ª±c thi ch·ªãu tr√°ch nhi·ªám ph√¢n ph·ªëi v√† th·ª±c thi c√¥ng vi·ªác.
- **Th∆∞ vi·ªán chu·∫©n (Built-in libraries):** c√°c th√†nh ph·∫ßn c·∫•p cao x√¢y d·ª±ng tr√™n l√µi ƒë·ªÉ cung c·∫•p c√°c kh·∫£ nƒÉng x·ª≠ l√Ω d·ªØ li·ªáu chuy√™n bi·ªát, bao g·ªìm:
    - **Spark SQL:** x·ª≠ l√Ω d·ªØ li·ªáu c√≥ c·∫•u tr√∫c v√† b√°n c·∫•u tr√∫c, h·ªó tr·ª£ truy v·∫•n SQL.
    - **Spark Streaming:** x·ª≠ l√Ω d·ªØ li·ªáu lu·ªìng th·ªùi gian th·ª±c.
    - **MLlib:** th∆∞ vi·ªán h·ªçc m√°y cung c·∫•p c√°c thu·∫≠t to√°n v√† c√¥ng c·ª• h·ªçc m√°y.
    - **GraphX:** x·ª≠ l√Ω v√† ph√¢n t√≠ch d·ªØ li·ªáu ƒë·ªì th·ªã.
- **H·ªá th·ªëng m·ªü r·ªông (higher-level systems):** c√°c th√†nh ph·∫ßn ph√≠a tr√™n l√µi cung c·∫•p kh·∫£ nƒÉng x·ª≠ l√Ω chuy√™n bi·ªát (v√≠ d·ª•: thi·∫øt k·∫ø pipeline x·ª≠ l√Ω lu·ªìng).
    - **PySpark:** API ch√≠nh th·ª©c cho Python
    - **SparkR:** API ch√≠nh th·ª©c cho R
    - **Scala API:** API ch√≠nh th·ª©c cho Scala
    - **Java API:** API ch√≠nh th·ª©c cho Java

H√¨nh d∆∞·ªõi ƒë√¢y ƒë∆∞·ª£c l·∫•y t·ª´ cu·ªën s√°ch [Hadoop in practice - Second edition](https://github.com/MinhHuuNguyen/data-engineer-lectures/blob/master/books/hadoop_in_practice_second_edition_alex_holmes.pdf), m√¥ t·∫£ c√°c th√†nh ph·∫ßn ch√≠nh trong ki·∫øn tr√∫c c·ªßa Apache Spark.

<img src="https://raw.githubusercontent.com/MinhHuuNguyen/data-engineer-lectures/refs/heads/master/3_hadoop_ecosystem/images/5-spark/components.jpeg" style="width: 800px;"/>

### 2.2. Ki·∫øn tr√∫c c·ªßa Spark

C·ª•m m√°y m√† Spark s·ª≠ d·ª•ng ƒë·ªÉ th·ª±c thi c√°c t√°c v·ª• ƒë∆∞·ª£c qu·∫£n l√Ω b·ªüi m·ªôt tr√¨nh qu·∫£n l√Ω c·ª•m.
Ch√∫ng ta g·ª≠i c√°c ·ª®ng d·ª•ng Spark (Spark Applications) t·ªõi nh·ªØng tr√¨nh qu·∫£n l√Ω c·ª•m n√†y; c√°c tr√¨nh qu·∫£n l√Ω s·∫Ω c·∫•p t√†i nguy√™n cho ·ª©ng d·ª•ng c·ªßa ch√∫ng ta ƒë·ªÉ ho√†n th√†nh c√¥ng vi·ªác.

Ki·∫øn tr√∫c c·ªßa Spark ƒë∆∞·ª£c chia l√†m ba th√†nh ph·∫ßn ch√≠nh:
- **Tr√¨nh qu·∫£n l√Ω c·ª•m (Cluster Manager):** Qu·∫£n l√Ω m√°y v·∫≠t l√Ω v√† t√†i nguy√™n (v√≠ d·ª•: Spark Standalone, YARN, Mesos).
- **·ª®ng d·ª•ng Spark (Spark Application):** G·ªìm m·ªôt driver v√† nhi·ªÅu executor.
    - **Driver:** Ch·∫°y main(), duy tr√¨ tr·∫°ng th√°i ·ª©ng d·ª•ng, nh·∫≠n/ƒë√°p ·ª©ng ƒë·∫ßu v√†o, ph√¢n t√≠ch v√† l·∫≠p l·ªãch c√¥ng vi·ªác.
    - **Executor:** Th·ª±c thi m√£ do driver giao, l∆∞u tr·ªØ v√† b√°o c√°o tr·∫°ng th√°i t√≠nh to√°n.

H√¨nh d∆∞·ªõi ƒë√¢y ƒë∆∞·ª£c l·∫•y t·ª´ cu·ªën s√°ch [Hadoop in practice - Second edition](https://github.com/MinhHuuNguyen/data-engineer-lectures/blob/master/books/hadoop_in_practice_second_edition_alex_holmes.pdf), m√¥ t·∫£ ki·∫øn tr√∫c c·ªßa Apache Spark.

<img src="https://raw.githubusercontent.com/MinhHuuNguyen/data-engineer-lectures/refs/heads/master/3_hadoop_ecosystem/images/5-spark/architecture.jpeg" style="width: 800px;"/>

Spark ho·∫°t ƒë·ªông ph√¢n t√°ch r√µ r√†ng gi·ªØa th√†nh ph·∫ßn ƒëi·ªÅu ph·ªëi (driver), th√†nh ph·∫ßn th·ª±c thi (executors) v√† l·ªõp qu·∫£n l√Ω t√†i nguy√™n (cluster manager), cho ph√©p th·ª±c thi ph√¢n t√°n, linh ho·∫°t v√† c√≥ th·ªÉ ch·∫°y nhi·ªÅu ·ª©ng d·ª•ng ƒë·ªìng th·ªùi tr√™n c√πng m·ªôt c·ª•m.

Tasks ƒë∆∞·ª£c l·∫≠p l·ªãch v√† ph√¢n ph·ªëi b·ªüi driver t·ªõi c√°c executors, t·∫≠n d·ª•ng t√†i nguy√™n ƒë∆∞·ª£c c·∫•p ph√°t b·ªüi cluster manager.
Cache l√† b·ªô nh·ªõ ƒë·ªám ph√¢n t√°n tr√™n c√°c executors ƒë·ªÉ l∆∞u tr·ªØ d·ªØ li·ªáu t·∫°m th·ªùi, gi√∫p tƒÉng t·ªëc ƒë·ªô truy c·∫≠p d·ªØ li·ªáu trong c√°c t√°c v·ª• l·∫∑p l·∫°i.

Driver c√≥ th·ªÉ ƒë∆∞·ª£c ƒëi·ªÅu khi·ªÉn t·ª´ nhi·ªÅu ng√¥n ng·ªØ th√¥ng qua c√°c API (Scala/Java/Python/R), trong khi executors ch·ªãu tr√°ch nhi·ªám th·ª±c thi c√¥ng vi·ªác.

### 2.3. Spark t∆∞∆°ng t√°c v·ªõi YARN

Spark h·ªó tr·ª£ nhi·ªÅu tr√¨nh qu·∫£n l√Ω c·ª•m, trong ƒë√≥ c√≥ YARN.
·ªû ch·∫ø ƒë·ªô n√†y, c√°c executor c·ªßa Spark l√† c√°c container do YARN qu·∫£n l√Ω, v√† ApplicationMaster c·ªßa Spark ch·ªãu tr√°ch nhi·ªám qu·∫£n l√Ω c√°c executor ƒë√≥ v√† g·ª≠i l·ªánh cho ch√∫ng.

H√¨nh d∆∞·ªõi ƒë√¢y ƒë∆∞·ª£c l·∫•y t·ª´ cu·ªën s√°ch [Hadoop in practice - Second edition](https://github.com/MinhHuuNguyen/data-engineer-lectures/blob/master/books/hadoop_in_practice_second_edition_alex_holmes.pdf), m√¥ t·∫£ c√°ch Spark t∆∞∆°ng t√°c v·ªõi YARN ƒë·ªÉ qu·∫£n l√Ω t√†i nguy√™n v√† th·ª±c thi c√¥ng vi·ªác.

<img src="https://raw.githubusercontent.com/MinhHuuNguyen/data-engineer-lectures/refs/heads/master/3_hadoop_ecosystem/images/5-spark/spark_yarn.jpeg" style="width: 800px;"/>

Driver c·ªßa Spark c√≥ th·ªÉ n·∫±m trong ti·∫øn tr√¨nh client ho·∫∑c b√™n trong ApplicationMaster, t√πy thu·ªôc v√†o vi·ªác b·∫°n ch·∫°y ·ªü client mode hay cluster mode:
- **Client mode:** driver n·∫±m trong ti·∫øn tr√¨nh client; do ƒë√≥, n·∫øu ti·∫øn tr√¨nh client b·ªã d·ª´ng th√¨ vi·ªác th·ª±c thi chu·ªói c√°c t√°c v·ª• Spark s·∫Ω b·ªã gi√°n ƒëo·∫°n.
Ch·∫ø ƒë·ªô n√†y ph√π h·ª£p cho m√¥i tr∆∞·ªùng development v·ªõi d·ªØ li·ªáu nh·ªè, d√πng trong qu√° tr√¨nh debug, quan s√°t log v√† tr·∫°ng th√°i driver d·ªÖ d√†ng.
- **Cluster mode:** driver ch·∫°y b√™n trong ApplicationMaster v√† kh√¥ng ph·ª• thu·ªôc v√†o ti·∫øn tr√¨nh client ƒë·ªÉ th·ª±c thi c√°c t√°c v·ª•.
Ch·∫ø ƒë·ªô n√†y ph√π h·ª£p cho m√¥i tr∆∞·ªùng production v·ªõi d·ªØ li·ªáu l·ªõn, gi√∫p tƒÉng t√≠nh ·ªïn ƒë·ªãnh v√† kh·∫£ nƒÉng ch·ªãu l·ªói.

C√†i ƒë·∫∑t m·∫∑c ƒë·ªãnh c·ªßa Spark ƒë∆∞·ª£c c·∫•u h√¨nh cho ch·∫ø ƒë·ªô standalone, n√™n b·∫°n c·∫ßn c·∫•u h√¨nh Spark ƒë·ªÉ n√≥ ho·∫°t ƒë·ªông v·ªõi YARN.
C√°c script v√† c√¥ng c·ª• Spark kh√¥ng thay ƒë·ªïi khi ch·∫°y tr√™n YARN; v√¨ v·∫≠y m·ªôt khi ƒë√£ c·∫•u h√¨nh ƒë·ªÉ d√πng YARN, b·∫°n c√≥ th·ªÉ ch·∫°y Spark shell gi·ªëng nh∆∞ tr∆∞·ªõc.

## 3. Th√†nh ph·∫ßn c·ªët l√µi Spark Core

Spark Core l√† ‚Äútr√°i tim‚Äù c·ªßa Spark, cung c·∫•p n·ªÅn t·∫£ng th·ª±c thi v√† c√°c c∆° ch·∫ø c·ªët l√µi cho m·ªçi ·ª©ng d·ª•ng Spark.
M·ªôt s·ªë c√¥ng ngh·ªá quan tr·ªçng trong Spark Core bao g·ªìm Ki·ªÉu d·ªØ li·ªáu RDD, C∆° ch·∫ø ƒë√°nh gi√° l∆∞·ªùi (Lazy evaluation) v√† B·ªô t·ªëi ∆∞u h√≥a Catalyst (Catalyst Optimizer).

### 3.1. Resilient Distributed Dataset (RDD)

Resilient Distributed Dataset (RDD) l√† c·∫•u tr√∫c d·ªØ li·ªáu quan tr·ªçng nh·∫•t trong Apache Spark, l√† t·∫≠p h·ª£p d·ªØ li·ªáu b·∫•t bi·∫øn ƒë∆∞·ª£c ph√¢n t√°n tr√™n c√°c node c·ªßa c·ª•m, cho ph√©p x·ª≠ l√Ω song song.
RDD l√† m·ªôt kh√°i ni·ªám quan tr·ªçng trong Spark Core ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ l∆∞u tr·ªØ v√† x·ª≠ l√Ω d·ªØ li·ªáu tr√™n m·ªôt c·ª•m m√°y t√≠nh ph√¢n t√°n.

H√¨nh d∆∞·ªõi ƒë√¢y ƒë∆∞·ª£c l·∫•y t·ª´ cu·ªën s√°ch [Spark: The definitive Guide](https://github.com/MinhHuuNguyen/data-engineer-lectures/blob/master/books/spark_the_definitive_guide_bill_chambers_matei_zaharia.pdf), m√¥ t·∫£ s·ª± ph√¢n t√°n d·ªØ li·ªáu tr√™n c√°c server trong c·ª•m Spark.

<img src="https://raw.githubusercontent.com/MinhHuuNguyen/data-engineer-lectures/refs/heads/master/3_hadoop_ecosystem/images/5-spark/data_across_server.jpeg" style="width: 600px;"/>

RDD chia d·ªØ li·ªáu th√†nh c√°c ph·∫ßn nh·ªè v√† ph√¢n t√°n ch√∫ng tr√™n c√°c n√∫t trong c·ª•m, trong ƒë√≥, m·ªói ph·∫ßn d·ªØ li·ªáu ƒë∆∞·ª£c l∆∞u tr·ªØ tr√™n m·ªôt n√∫t v√† c√≥ th·ªÉ x·ª≠ l√Ω m·ªôt c√°ch ƒë·ªôc l·∫≠p.

Ngo√†i ra, RDD c√≥ kh·∫£ nƒÉng l∆∞u tr·ªØ d·ªØ li·ªáu trong b·ªô nh·ªõ RAM, gi√∫p t·ªëi ∆∞u h√≥a hi·ªáu su·∫•t x·ª≠ l√Ω d·ªØ li·ªáu.
Khi d·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c l∆∞u tr·ªØ trong b·ªô nh·ªõ, c√°c ph√©p t√≠nh to√°n sau n√†y tr√™n RDD c√≥ th·ªÉ ƒë∆∞·ª£c th·ª±c hi·ªán nhanh h∆°n v√¨ kh√¥ng c·∫ßn ƒë·ªçc d·ªØ li·ªáu t·ª´ ƒëƒ©a.

H√¨nh d∆∞·ªõi ƒë√¢y ƒë∆∞·ª£c l·∫•y t·ª´ cu·ªën s√°ch [Spark: The definitive Guide](https://github.com/MinhHuuNguyen/data-engineer-lectures/blob/master/books/spark_the_definitive_guide_bill_chambers_matei_zaharia.pdf), m√¥ t·∫£ s·ª± so s√°nh gi·ªØa Narrow transformations v√† Wide transformations trong RDD.

<img src="https://raw.githubusercontent.com/MinhHuuNguyen/data-engineer-lectures/refs/heads/master/3_hadoop_ecosystem/images/5-spark/narrow_wide_transformations.jpeg" style="width: 600px;"/>

C√≥ hai lo·∫°i to√°n t·ª≠ t∆∞∆°ng t√°c v·ªõi RDD:
- **Transformation** l√† c√°c to√°n t·ª≠ tr·∫£ ƒë·∫ßu ra l√† m·ªôt RDD m·ªõi sau khi th·ª±c hi·ªán bi·∫øn ƒë·ªïi RDD
    - **Narrow transformations**
        - L√† c√°c ph√©p bi·∫øn ƒë·ªïi m√† m·ªói ph·∫ßn t·ª≠ ƒë·∫ßu ra ch·ªâ ph·ª• thu·ªôc v√†o m·ªôt v√†i ph·∫ßn t·ª≠ ƒë·∫ßu v√†o v√† kh√¥ng c·∫ßn truy c·∫≠p ƒë·∫øn t·∫•t c·∫£ c√°c ph·∫ßn t·ª≠ trong c√°c ph√¢n v√πng (partitions) c·ªßa RDD.
        - Th·ª±c hi·ªán song song tr√™n t·ª´ng ph√¢n v√πng ri√™ng l·∫ª m√† kh√¥ng c·∫ßn giao ti·∫øp ho·∫∑c trao ƒë·ªïi d·ªØ li·ªáu gi·ªØa c√°c ph√¢n v√πng.
        Do ƒë√≥, ch√∫ng c√≥ hi·ªáu su·∫•t cao h∆°n v√† kh√¥ng y√™u c·∫ßu nhi·ªÅu b∆∞·ªõc t√≠nh to√°n ph·ª©c t·∫°p.
        - V√≠ d·ª•: select, map, filter ...
    - **Wide transformations**: D·ªØ li·ªáu c·∫ßn ƒë·ªÉ th·ª±c hi·ªán bi·∫øn ƒë·ªïi n·∫±m tr√™n c√°c partition kh√°c nhau
        - L√† c√°c ph√©p bi·∫øn ƒë·ªïi m√† m·ªói ph·∫ßn t·ª≠ ƒë·∫ßu ra c√≥ th·ªÉ ph·ª• thu·ªôc v√†o t·∫•t c·∫£ c√°c ph·∫ßn t·ª≠ trong c√°c ph√¢n v√πng c·ªßa RDD ho·∫∑c c√≥ kh·∫£ nƒÉng giao ti·∫øp v√† trao ƒë·ªïi d·ªØ li·ªáu gi·ªØa c√°c ph√¢n v√πng.
        - Th∆∞·ªùng g√¢y ra s·ª± di chuy·ªÉn d·ªØ li·ªáu gi·ªØa c√°c ph√¢n v√πng, ƒë√≤i h·ªèi nhi·ªÅu b∆∞·ªõc t√≠nh to√°n v√† c√≥ th·ªÉ l√†m gi·∫£m hi·ªáu su·∫•t
        - V√≠ d·ª•: groupBy, join, sort, ...
- **Action** l√† c√°c to√°n t·ª≠ tr·∫£ ƒë·∫ßu ra l√† c√°c gi√° tr·ªã sau khi th·ª±c hi·ªán t√≠nh to√°n tr√™n RDD. V√≠ d·ª•: show, count, first, save, ...

### 3.2. C∆° ch·∫ø Lazy evaluation

Lazy evaluation kh√¥ng ph·∫£i l√† c∆° ch·∫ø ƒë∆∞·ª£c s√°ng t·∫°o b·ªüi nh√† ph√°t tri·ªÉn c·ªßa Spark nh∆∞ng ƒë∆∞·ª£c ·ª©ng d·ª•ng v√†o RDD c·ªßa Spark gi√∫p tƒÉng t·ªëc hi·ªáu qu·∫£ x·ª≠ l√Ω d·ªØ li·ªáu l·ªõn.

C√≥ hai chi·∫øn l∆∞·ª£c ƒë·ªëi ngh·ªãch nhau l√† Lazy Evaluation v√† Eager Evaluation:
- **Lazy Evaluation**:
    - L√† m·ªôt ph∆∞∆°ng ph√°p trong ƒë√≥ bi·ªÉu th·ª©c ho·∫∑c t√≠nh to√°n kh√¥ng ƒë∆∞·ª£c ƒë√°nh gi√° ngay l·∫≠p t·ª©c khi ch√∫ng ƒë∆∞·ª£c t·∫°o ra.
    Thay v√†o ƒë√≥, ch√∫ng ƒë∆∞·ª£c l∆∞u tr·ªØ t·∫°m th·ªùi v√† ch·ªâ ƒë∆∞·ª£c t√≠nh to√°n khi c·∫ßn thi·∫øt.
    - Gi√∫p t·ªëi ∆∞u h√≥a vi·ªác s·ª≠ d·ª•ng t√†i nguy√™n b·∫±ng c√°ch tr√°nh t√≠nh to√°n kh√¥ng c·∫ßn thi·∫øt.
    N√≥ ƒë·∫∑c bi·ªát h·ªØu √≠ch khi l√†m vi·ªác v·ªõi d·ªØ li·ªáu l·ªõn ho·∫∑c trong c√°c t√¨nh hu·ªëng c·∫ßn t·ªëi ∆∞u h√≥a hi·ªáu su·∫•t.
- **Eager Evaluation**:
    - L√† ph∆∞∆°ng ph√°p trong ƒë√≥ bi·ªÉu th·ª©c ho·∫∑c t√≠nh to√°n ƒë∆∞·ª£c ƒë√°nh gi√° ngay l·∫≠p t·ª©c khi ch√∫ng ƒë∆∞·ª£c t·∫°o ra.
    C√°c gi√° tr·ªã k·∫øt qu·∫£ ƒë∆∞·ª£c t√≠nh to√°n v√† l∆∞u tr·ªØ ngay sau khi bi·ªÉu th·ª©c ƒë∆∞·ª£c g·ªçi.
    - D·ªÖ d√†ng ƒë·ªÉ hi·ªÉu v√† debug v√¨ t·∫•t c·∫£ c√°c bi·ªÉu th·ª©c v√† t√≠nh to√°n ƒë·ªÅu ƒë∆∞·ª£c th·ª±c hi·ªán ngay l·∫≠p t·ª©c.
    - C√≥ th·ªÉ g√¢y l√£ng ph√≠ t√†i nguy√™n v√† th·ªùi gian n·∫øu c√°c t√≠nh to√°n kh√¥ng c·∫ßn thi·∫øt ƒë∆∞·ª£c th·ª±c hi·ªán.

V√≠ d·ª•:
```python
# V√≠ d·ª• s·ª≠ d·ª•ng Lazy Evaluation
def lazy_add(a, b):
    return lambda: a + b

result = lazy_add(3, 4)  # Kh√¥ng th·ª±c hi·ªán ph√©p c·ªông ngay l·∫≠p t·ª©c
print("Bi·ªÉu th·ª©c v·∫´n ch∆∞a ƒë∆∞·ª£c t√≠nh to√°n")
print("K·∫øt qu·∫£ sau khi t√≠nh to√°n:", result())  # Khi c·∫ßn, bi·ªÉu th·ª©c m·ªõi ƒë∆∞·ª£c t√≠nh to√°n
```

```python
# V√≠ d·ª• s·ª≠ d·ª•ng Eager Evaluation
def eager_add(a, b):
    return a + b

result = eager_add(3, 4)  # Th·ª±c hi·ªán ph√©p c·ªông ngay l·∫≠p t·ª©c
print("Bi·ªÉu th·ª©c ƒë√£ ƒë∆∞·ª£c t√≠nh to√°n")
print("K·∫øt qu·∫£ sau khi t√≠nh to√°n:", result)  # K·∫øt qu·∫£ ƒë√£ ƒë∆∞·ª£c t√≠nh to√°n tr∆∞·ªõc ƒë√≥
```

Trong Spark, Lazy evaluation cho ph√©p ta ƒë·ªãnh nghƒ©a nhi·ªÅu ph√©p bi·∫øn ƒë·ªïi d·ªØ li·ªáu (Transformation) tr∆∞·ªõc khi ch√∫ng ƒë∆∞·ª£c th·ª±c s·ª± ti·∫øn h√†nh khi m·ªôt h√†nh ƒë·ªông (Action) ƒë∆∞·ª£c g·ªçi.
**Do ƒë√≥, Transformations are LAZY but Actions are EAGER.**

V√≠ d·ª•: Ta c√≥ m·ªôt RDD ch·ª©a d·ªØ li·ªáu c·ªßa c√°c h·ªçc sinh trong m·ªôt l·ªõp h·ªçc.
Ta mu·ªën t√≠nh t·ªïng ƒëi·ªÉm c·ªßa t·∫•t c·∫£ c√°c h·ªçc sinh trong l·ªõp.
ƒê·ªÉ l√†m ƒëi·ªÅu n√†y, ta c√≥ th·ªÉ s·ª≠ d·ª•ng ph∆∞∆°ng ph√°p Eager Evaluation nh∆∞ sau:

```python
# Eager Evaluation
# T√≠nh t·ªïng ƒëi·ªÉm c·ªßa t·∫•t c·∫£ c√°c h·ªçc sinh trong l·ªõp
total_score = 0
for student in students:
    total_score += student.score
```

Tuy nhi√™n, n·∫øu ta mu·ªën t√≠nh t·ªïng ƒëi·ªÉm c·ªßa c√°c h·ªçc sinh c√≥ ƒëi·ªÉm tr√™n 8, ta s·∫Ω ph·∫£i th·ª±c hi·ªán l·∫°i v√≤ng l·∫∑p tr√™n nh∆∞ sau:

```python
# Eager Evaluation
# T√≠nh t·ªïng ƒëi·ªÉm c·ªßa t·∫•t c·∫£ c√°c h·ªçc sinh c√≥ ƒëi·ªÉm tr√™n 8 trong l·ªõp
total_score = 0
for student in students:
    if student.score > 8:
        total_score += student.score
```

ƒê·ªÉ tr√°nh vi·ªác th·ª±c hi·ªán l·∫°i v√≤ng l·∫∑p, ta c√≥ th·ªÉ s·ª≠ d·ª•ng ph∆∞∆°ng ph√°p Lazy Evaluation nh∆∞ sau:

```python
# Lazy Evaluation
# T√≠nh t·ªïng ƒëi·ªÉm c·ªßa t·∫•t c·∫£ c√°c h·ªçc sinh trong l·ªõp
total_score = students.map(lambda student: student.score).reduce(lambda x, y: x + y)
```

```python
# Lazy Evaluation
# T√≠nh t·ªïng ƒëi·ªÉm c·ªßa t·∫•t c·∫£ c√°c h·ªçc sinh c√≥ ƒëi·ªÉm tr√™n 8 trong l·ªõp
total_score = students.filter(lambda student: student.score > 8).map(lambda student: student.score).reduce(lambda x, y: x + y)
```

### 3.3. Catalyst Optimizer

Catalyst l√† m·ªôt b·ªô t·ªëi ∆∞u h√≥a ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ c·∫£i thi·ªán hi·ªáu su·∫•t v√† t·ªëi ∆∞u h√≥a k·∫ø ho·∫°ch th·ª±c hi·ªán c√°c ƒëo·∫°n code logic x·ª≠ l√Ω d·ªØ li·ªáu.
N√≥ l√† m·ªôt b·ªô t·ªëi ∆∞u h√≥a d·ª±a tr√™n quy t·∫Øc (rule-based optimizer) v√† ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ bi·∫øn ƒë·ªïi ƒëo·∫°n code logic x·ª≠ l√Ω d·ªØ li·ªáu t·∫°o ra c√°c k·∫ø ho·∫°ch th·ª±c hi·ªán hi·ªáu qu·∫£ h∆°n.

H√¨nh d∆∞·ªõi ƒë√¢y ƒë∆∞·ª£c l·∫•y t·ª´ cu·ªën s√°ch [Spark: The definitive Guide](https://github.com/MinhHuuNguyen/data-engineer-lectures/blob/master/books/spark_the_definitive_guide_bill_chambers_matei_zaharia.pdf), m√¥ t·∫£ √Ω t∆∞·ªüng c·ªßa Catalyst Optimizer.

<img src="https://raw.githubusercontent.com/MinhHuuNguyen/data-engineer-lectures/refs/heads/master/3_hadoop_ecosystem/images/5-spark/catalyst_optimizer.jpeg" style="width: 800px;"/>

Qu√° tr√¨nh t·ªëi ∆∞u h√≥a trong Catalyst bao g·ªìm hai giai ƒëo·∫°n ch√≠nh: Logical Planning v√† Physical Planning.
Catalyst Optimizer chia qu√° tr√¨nh x·ª≠ l√Ω th√†nh hai t·∫ßng r√µ r√†ng, gi√∫p Spark ƒë·∫°t hi·ªáu nƒÉng cao v√† linh ho·∫°t.
- Logical planning t·ªëi ∆∞u ‚Äúc√°i g√¨ c·∫ßn l√†m‚Äù.
- Physical planning quy·∫øt ƒë·ªãnh ‚Äúl√†m nh∆∞ th·∫ø n√†o‚Äù tr√™n cluster.

ƒê·ªëi v·ªõi Logical Planning (l·∫≠p k·∫ø ho·∫°ch logic):
- **B∆∞·ªõc 1:** Spark chuy·ªÉn m√£ ng∆∞·ªùi d√πng th√†nh **unresolved logical plan**.
K·∫ø ho·∫°ch n√†y ƒë∆∞·ª£c g·ªçi l√† ‚Äúch∆∞a ƒë∆∞·ª£c ph√¢n gi·∫£i‚Äù v√¨ m·∫∑c d√π m√£ c√≥ th·ªÉ h·ª£p l·ªá v·ªÅ m·∫∑t c√∫ ph√°p, nh∆∞ng c√°c b·∫£ng ho·∫∑c c·ªôt m√† n√≥ tham chi·∫øu c√≥ th·ªÉ t·ªìn t·∫°i ho·∫∑c kh√¥ng t·ªìn t·∫°i.
- **B∆∞·ªõc 2:** Spark s·ª≠ d·ª•ng **catalog** ‚Äî kho l∆∞u tr·ªØ th√¥ng tin v·ªÅ t·∫•t c·∫£ c√°c b·∫£ng v√† DataFrame ‚Äî ƒë·ªÉ ph√¢n gi·∫£i t√™n b·∫£ng v√† c·ªôt.
·ªû ƒë√¢y, Spark c√≥ th·ªÉ t·ª´ ch·ªëi **unresolved logical plan** n·∫øu b·∫£ng ho·∫∑c c·ªôt kh√¥ng t·ªìn t·∫°i trong catalog.
N·∫øu c√≥ th·ªÉ ph√¢n gi·∫£i, k·∫ø ho·∫°ch s·∫Ω ƒë∆∞·ª£c g·ªçi l√† **logical plan** v√† chuy·ªÉn sang Catalyst Optimizer.
- **B∆∞·ªõc 3:** Catalyst √°p d·ª•ng m·ªôt lo·∫°t c√°c quy t·∫Øc t·ªëi ∆∞u h√≥a ƒë·ªÉ bi·∫øn ƒë·ªïi **logical plan** th√†nh **optimized logical plan** nh∆∞ ƒë·∫©y ƒëi·ªÅu ki·ªán l·ªçc (predicate pushdown), s·∫Øp x·∫øp l·∫°i c√°c ph√©p n·ªëi (join reordering), lo·∫°i b·ªè c√°c c·ªôt d∆∞ th·ª´a (projection pruning) v√† lo·∫°i b·ªè c√°c b∆∞·ªõc trung gian kh√¥ng c·∫ßn thi·∫øt.
C√°c g√≥i m·ªü r·ªông c√≥ th·ªÉ b·ªï sung th√™m lu·∫≠t t·ªëi ∆∞u ri√™ng cho nh·ªØng b√†i to√°n chuy√™n bi·ªát.
- **B∆∞·ªõc 4:** K·∫ø ho·∫°ch logic t·ªëi ∆∞u **optimized logical plan** s·∫Ω ƒë∆∞·ª£c chuy·ªÉn sang giai ƒëo·∫°n l·∫≠p k·∫ø ho·∫°ch v·∫≠t l√Ω.

H√¨nh d∆∞·ªõi ƒë√¢y ƒë∆∞·ª£c l·∫•y t·ª´ cu·ªën s√°ch [Spark: The definitive Guide](https://github.com/MinhHuuNguyen/data-engineer-lectures/blob/master/books/spark_the_definitive_guide_bill_chambers_matei_zaharia.pdf), m√¥ t·∫£ √Ω t∆∞·ªüng c·ªßa Logical Plan trong Catalyst Optimizer.

<img src="https://raw.githubusercontent.com/MinhHuuNguyen/data-engineer-lectures/refs/heads/master/3_hadoop_ecosystem/images/5-spark/logical_plan.jpeg" style="width: 800px;"/>

Physical plan (th∆∞·ªùng ƒë∆∞·ª£c g·ªçi l√† Spark plan) m√¥ t·∫£ c√°ch **optimized logical plan** s·∫Ω ƒë∆∞·ª£c th·ª±c thi tr√™n cluster b·∫±ng c√°ch sinh ra nhi·ªÅu chi·∫øn l∆∞·ª£c th·ª±c thi v·∫≠t l√Ω kh√°c nhau v√† so s√°nh ch√∫ng th√¥ng qua m·ªôt m√¥ h√¨nh chi ph√≠ (cost model).

K·∫øt qu·∫£ c·ªßa physical planning l√† m·ªôt chu·ªói c√°c RDD v√† c√°c ph√©p bi·∫øn ƒë·ªïi t∆∞∆°ng ·ª©ng.
ƒê√¢y l√† l√Ω do Spark th∆∞·ªùng ƒë∆∞·ª£c xem nh∆∞ m·ªôt ‚Äútr√¨nh bi√™n d·ªãch‚Äù: n√≥ nh·∫≠n c√°c truy v·∫•n ·ªü m·ª©c DataFrame, Dataset ho·∫∑c SQL v√† bi√™n d·ªãch ch√∫ng th√†nh c√°c ph√©p bi·∫øn ƒë·ªïi RDD.
Sau khi ch·ªçn physical plan, Spark th·ª±c thi m√£ n√†y tr√™n RDD ‚Äî giao di·ªán l·∫≠p tr√¨nh m·ª©c th·∫•p c·ªßa Spark.

Trong qu√° tr√¨nh ch·∫°y, Spark ti·∫øp t·ª•c th·ª±c hi·ªán c√°c t·ªëi ∆∞u ·ªü th·ªùi gian th·ª±c, sinh bytecode Java g·ªëc c√≥ th·ªÉ lo·∫°i b·ªè to√†n b·ªô t√°c v·ª• ho·∫∑c stage kh√¥ng c·∫ßn thi·∫øt.
Cu·ªëi c√πng, k·∫øt qu·∫£ ƒë∆∞·ª£c tr·∫£ v·ªÅ cho ng∆∞·ªùi d√πng.

H√¨nh d∆∞·ªõi ƒë√¢y ƒë∆∞·ª£c l·∫•y t·ª´ cu·ªën s√°ch [Spark: The definitive Guide](https://github.com/MinhHuuNguyen/data-engineer-lectures/blob/master/books/spark_the_definitive_guide_bill_chambers_matei_zaharia.pdf), m√¥ t·∫£ √Ω t∆∞·ªüng c·ªßa Physical Plan trong Catalyst Optimizer.

<img src="https://raw.githubusercontent.com/MinhHuuNguyen/data-engineer-lectures/refs/heads/master/3_hadoop_ecosystem/images/5-spark/physical_plan.jpeg" style="width: 800px;"/>

V√≠ d·ª•: Gi·∫£ s·ª≠ ta c√≥ m·ªôt truy v·∫•n SQL nh∆∞ sau:

```sql
SELECT c.customer_id, c.name, o.order_id, o.amount
FROM customers c
JOIN orders o
  ON c.customer_id = o.customer_id
WHERE o.amount > 100 AND c.country = 'US';
```

K·∫øt qu·∫£ t·ªëi ∆∞u c·ªßa c√¢u truy v·∫•n tr√™n nh∆∞ sau:

```
Project [c.customer_id#10, c.name#11, o.order_id#20, o.amount#21]
+- Join Inner, (c.customer_id#10 = o.customer_id#22)
   :- Project [customer_id#10, name#11]
   :  +- Filter (country#12 = US)
   :     +- Relation customers [customer_id#10, name#11, country#12]   -- projection pruning
   +- Project [order_id#20, customer_id#22, amount#21]
      +- Filter (amount#21 > 100)
         +- Relation orders [order_id#20, customer_id#22, amount#21]  -- projection pruning
```

Nh·ªØng thay ƒë·ªïi ch√≠nh so v·ªõi k·∫ø ho·∫°ch ƒë√£ ph√¢n gi·∫£i:
- **Predicate pushdown:** c.country = 'US' ƒë∆∞·ª£c ƒë·∫©y xu·ªëng ph√≠a customers relation; o.amount > 100 ƒë∆∞·ª£c ƒë·∫©y xu·ªëng orders relation. ƒêi·ªÅu n√†y gi·∫£m l∆∞·ª£ng d·ªØ li·ªáu truy·ªÅn ƒë·∫øn b∆∞·ªõc Join.
- **Projection pruning:** ch·ªâ gi·ªØ c√°c c·ªôt c·∫ßn thi·∫øt (v√≠ d·ª• signup_date, age, status, created_at b·ªã lo·∫°i kh·ªèi scan).
- Catalyst optimizer c√≥ th·ªÉ quy·∫øt ƒë·ªãnh th·ª© t·ª± join ho·∫∑c ch·ªçn thu·∫≠t to√°n join ph√π h·ª£p (th∆∞·ªùng xu·∫•t hi·ªán ·ªü physical planning).

## 4. C√°c th√†nh ph·∫ßn c·∫•p cao c·ªßa Spark

### 4.1. SparkSQL

Spark SQL ƒë√≥ng vai tr√≤ l√† l·ªõp x·ª≠ l√Ω d·ªØ li·ªáu c√≥ c·∫•u tr√∫c trong h·ªá sinh th√°i Spark.
Spark SQL c√≥ th·ªÉ n·∫°p d·ªØ li·ªáu t·ª´ nhi·ªÅu ngu·ªìn d·ªØ li·ªáu c√≥ c·∫•u tr√∫c kh√°c nhau (v√≠ d·ª•: JSON, Hive v√† Parquet).

Spark SQL cho ph√©p ng∆∞·ªùi d√πng truy v·∫•n d·ªØ li·ªáu b·∫±ng SQL, c·∫£ ·ªü b√™n trong ch∆∞∆°ng tr√¨nh Spark l·∫´n t·ª´ c√°c c√¥ng c·ª• b√™n ngo√†i k·∫øt n·ªëi t·ªõi Spark SQL th√¥ng qua c√°c chu·∫©n k·∫øt n·ªëi c∆° s·ªü d·ªØ li·ªáu (nh∆∞ Chu·∫©n k·∫øt n·ªëi c∆° s·ªü d·ªØ li·ªáu d√†nh cho ng√¥n ng·ªØ Java: Java Database Connectivity - JDBC hay Chu·∫©n k·∫øt n·ªëi c∆° s·ªü d·ªØ li·ªáu ƒë·ªôc l·∫≠p ng√¥n ng·ªØ l·∫≠p tr√¨nh: Open Database Connectivity - ODBC).
T·ª´ ƒë√≥, c√°c c√¥ng c·ª• ph√¢n t√≠ch nghi·ªáp v·ª• (Business Intelligence) nh∆∞ Tableau, QlikView v√† Power BI c√≥ th·ªÉ k·∫øt n·ªëi tr·ª±c ti·∫øp t·ªõi Spark SQL ƒë·ªÉ truy v·∫•n v√† tr·ª±c quan h√≥a d·ªØ li·ªáu.

H√¨nh d∆∞·ªõi ƒë√¢y ƒë∆∞·ª£c l·∫•y t·ª´ cu·ªën s√°ch [Learning Spark: LIGHTNING-FAST DATA ANALYSIS](https://github.com/MinhHuuNguyen/data-engineer-lectures/blob/master/books/learning_spark_lightning_fast_big_data_analysis_holden_karau_andy_konwinski_patrick_wendell_matei_zaharia.pdf), m√¥ t·∫£ lu·ªìng ho·∫°t ƒë·ªông c∆° b·∫£n c·ªßa Machine Learning.

<img src="https://raw.githubusercontent.com/MinhHuuNguyen/data-engineer-lectures/refs/heads/master/3_hadoop_ecosystem/images/5-spark/spark_sql.jpeg" style="width: 800px;"/>

Khi ƒë∆∞·ª£c s·ª≠ d·ª•ng b√™n trong m·ªôt ch∆∞∆°ng tr√¨nh Spark, Spark SQL cung c·∫•p kh·∫£ nƒÉng t√≠ch h·ª£p ch·∫∑t ch·∫Ω gi·ªØa SQL v√† m√£ Python/Java/Scala, bao g·ªìm vi·ªác cho ph√©p join gi·ªØa RDD v√† c√°c b·∫£ng SQL, ƒë·ªãnh nghƒ©a v√† s·ª≠ d·ª•ng c√°c h√†m t√πy bi·∫øn trong SQL, c√πng nhi·ªÅu kh·∫£ nƒÉng m·ªü r·ªông kh√°c.
Nhi·ªÅu t√°c v·ª• x·ª≠ l√Ω d·ªØ li·ªáu tr·ªü n√™n d·ªÖ tri·ªÉn khai h∆°n nh·ªù s·ª± k·∫øt h·ª£p n√†y.

#### So s√°nh gi·ªØa Spark SQL v√† Hive

| Ti√™u ch√≠           | **Hive**                                   | **Spark SQL**                        |
| ------------------ | ------------------------------------------ | ------------------------------------ |
| M·ª•c ti√™u ch√≠nh     | Data warehouse tr√™n Hadoop                 | X·ª≠ l√Ω d·ªØ li·ªáu c√≥ c·∫•u tr√∫c tr√™n Spark |
| Engine th·ª±c thi    | MapReduce / Tez / Spark                    | Spark engine (in-memory)             |
| Hi·ªáu nƒÉng          | Trung b√¨nh ‚Üí th·∫•p (ƒë·∫∑c bi·ªát v·ªõi MapReduce) | Cao, ƒë·ªô tr·ªÖ th·∫•p                     |
| ƒê·ªô tr·ªÖ truy v·∫•n    | Cao (ph√∫t)                                 | Th·∫•p (gi√¢y)                          |
| X·ª≠ l√Ω trong b·ªô nh·ªõ | Kh√¥ng / h·∫°n ch·∫ø                            | C√≥                                   |
| Ng√¥n ng·ªØ           | HiveQL                                     | SQL chu·∫©n + DataFrame/Dataset API    |
| T√≠ch h·ª£p v·ªõi code  | H·∫°n ch·∫ø                                    | R·∫•t ch·∫∑t ch·∫Ω (Python/Scala/Java)     |
| Qu·∫£n l√Ω metadata   | Hive Metastore                             | Th∆∞·ªùng d√πng chung Hive Metastore     |
| Kh·∫£ nƒÉng m·ªü r·ªông   | T·ªët cho batch l·ªõn                          | T·ªët cho batch v√† interactive         |
| T√≠nh linh ho·∫°t     | Th·∫•p h∆°n                                   | Cao h∆°n                              |

- **Hive:** ph√π h·ª£p cho l∆∞u tr·ªØ v√† ph√¢n t√≠ch batch quy m√¥ l·ªõn, √≠t y√™u c·∫ßu th·ªùi gian ph·∫£n h·ªìi.
- **Spark SQL:** ph√π h·ª£p cho x·ª≠ l√Ω nhanh, t∆∞∆°ng t√°c, v√† ph√¢n t√≠ch n√¢ng cao.

**Th·ª±c t·∫ø tri·ªÉn khai ph·ªï bi·∫øn: üëâ Hive Metastore + Spark SQL l√†m engine x·ª≠ l√Ω.**

#### So s√°nh gi·ªØa RDD, DataFrame, Dataset v√† Database/Metastore

| Ti√™u ch√≠           | **RDD**                       | **DataFrame**          | **Dataset**              | **Database / Metastore** |
| ------------------ | ----------------------------- | ---------------------- | ------------------------ | ------------------------ |
| B·∫£n ch·∫•t           | T·∫≠p d·ªØ li·ªáu ph√¢n t√°n m·ª©c th·∫•p | B·∫£ng d·ªØ li·ªáu c√≥ schema | DataFrame c√≥ type-safety | L·ªõp qu·∫£n l√Ω metadata     |
| M·ª©c tr·ª´u t∆∞·ª£ng     | Th·∫•p                          | Trung b√¨nh             | Trung b√¨nh‚Äìcao           | Cao                      |
| Schema             | Kh√¥ng                         | C√≥                     | C√≥                       | Qu·∫£n l√Ω schema           |
| Type-safety        | C√≥ (Scala/Java)               | Kh√¥ng                  | C√≥ (Scala/Java)          | Kh√¥ng √°p d·ª•ng            |
| Catalyst Optimizer | Kh√¥ng                         | C√≥                     | C√≥                       | Kh√¥ng                    |
| API ch√≠nh          | map, filter, reduce           | select, groupBy, SQL   | Typed ops + SQL          | SQL DDL, catalog         |
| Hi·ªáu nƒÉng          | Th·∫•p h∆°n                      | Cao                    | Cao                      | Kh√¥ng x·ª≠ l√Ω tr·ª±c ti·∫øp    |
| M·ª•c ƒë√≠ch s·ª≠ d·ª•ng   | X·ª≠ l√Ω t√πy bi·∫øn, low-level     | ETL, analytics, BI     | Pipeline typed (Scala)   | Qu·∫£n l√Ω b·∫£ng & schema    |
| Quan h·ªá v·ªõi Spark  | N·ªÅn t·∫£ng x·ª≠ l√Ω                | L·ªõp x·ª≠ l√Ω ch√≠nh        | L·ªõp x·ª≠ l√Ω n√¢ng cao       | H·ªó tr·ª£ truy v·∫•n          |

- **RDD:** ki·ªÉm so√°t th·∫•p t·∫ßng, √≠t t·ªëi ∆∞u
- **DataFrame:** b·∫£ng d·ªØ li·ªáu, hi·ªáu nƒÉng cao
- **Dataset:** DataFrame + type-safety
- **Database:** n∆°i qu·∫£n l√Ω schema v√† b·∫£ng, kh√¥ng tr·ª±c ti·∫øp x·ª≠ l√Ω d·ªØ li·ªáu

### 4.2. Spark Streaming

Spark Streaming l√† m·ªôt th√†nh ph·∫ßn quan tr·ªçng c·ªßa h·ªá sinh th√°i Apache Spark, ƒë∆∞·ª£c thi·∫øt k·∫ø ƒë·ªÉ x·ª≠ l√Ω v√† ph√¢n t√≠ch d·ªØ li·ªáu tr·ª±c ti·∫øp (real-time data) v·ªõi t·ªëc ƒë·ªô v√† kh·∫£ nƒÉng m·ªü r·ªông cao.
Spark Streaming t√≠ch h·ª£p ch·∫∑t ch·∫Ω v·ªõi Apache Spark, Spark Streaming c√≥ th·ªÉ s·ª≠ d·ª•ng API c·ªßa Java v√† Scala ·ªü b·∫£n Spark 1.1, v√† b·ªï sung th√™m API cho Python (PySpark) v√† R (SparkR) ·ªü c√°c b·∫£n sau ƒë√≥.

Spark Streaming x·ª≠ l√Ω d·ªØ li·ªáu tr·ª±c ti·∫øp t·ª´ nhi·ªÅu ngu·ªìn nh∆∞ streaming data (logs, s·ª± ki·ªán, d·ªØ li·ªáu sensor), batch data, v√† h·ªá th·ªëng h√†ng ƒë·ª£i tin nh·∫Øn (message queues) nh∆∞ Apache Kafka.

H√¨nh d∆∞·ªõi ƒë√¢y ƒë∆∞·ª£c l·∫•y t·ª´ cu·ªën s√°ch [Learning Spark: LIGHTNING-FAST DATA ANALYSIS](https://github.com/MinhHuuNguyen/data-engineer-lectures/blob/master/books/learning_spark_lightning_fast_big_data_analysis_holden_karau_andy_konwinski_patrick_wendell_matei_zaharia.pdf), m√¥ t·∫£ √Ω t∆∞·ªüng c·ªßa Spark Streaming.

<img src="https://raw.githubusercontent.com/MinhHuuNguyen/data-engineer-lectures/refs/heads/master/3_hadoop_ecosystem/images/5-spark/spark_streaming.jpeg" style="width: 800px;"/>

Spark Streaming kh√¥ng x·ª≠ l√Ω t·ª´ng b·∫£n ghi (record) ri√™ng l·∫ª, m√† x·ª≠ l√Ω d·ªØ li·ªáu theo c√°c l√¥ nh·ªè (micro-batch).
Spark Streaming s·ª≠ d·ª•ng ki·∫øn tr√∫c ‚Äúmicro-batch‚Äù, trong ƒë√≥ vi·ªác x·ª≠ l√Ω d·ªØ li·ªáu lu·ªìng ƒë∆∞·ª£c xem nh∆∞ m·ªôt chu·ªói li√™n t·ª•c c√°c ph√©p x·ª≠ l√Ω theo l√¥ (batch) tr√™n nh·ªØng t·∫≠p d·ªØ li·ªáu nh·ªè.
Spark Streaming nh·∫≠n d·ªØ li·ªáu t·ª´ nhi·ªÅu ngu·ªìn ƒë·∫ßu v√†o kh√°c nhau v√† gom ch√∫ng th√†nh c√°c l√¥ nh·ªè. C√°c l√¥ m·ªõi ƒë∆∞·ª£c t·∫°o ra theo nh·ªØng kho·∫£ng th·ªùi gian ƒë·ªÅu ƒë·∫∑n.

M·ªói batch t∆∞∆°ng ·ª©ng v·ªõi m·ªôt RDD, v√† ƒë∆∞·ª£c x·ª≠ l√Ω b·∫±ng c√°c ph√©p bi·∫øn ƒë·ªïi c·ªßa Spark gi·ªëng nh∆∞ x·ª≠ l√Ω batch truy·ªÅn th·ªëng.
Vi·ªác x·ª≠ l√Ω di·ªÖn ra tu·∫ßn t·ª± theo t·ª´ng batch, t·∫°o th√†nh m·ªôt chu·ªói c√°c Spark job li√™n ti·∫øp.
K·∫øt qu·∫£ x·ª≠ l√Ω ƒë∆∞·ª£c xu·∫•t ra c√°c h·ªá th·ªëng l∆∞u tr·ªØ ho·∫∑c d·ªãch v·ª• b√™n ngo√†i theo t·ª´ng batch.

B·∫£n ch·∫•t, Spark Streaming bi·∫øn b√†i to√°n x·ª≠ l√Ω d·ªØ li·ªáu th·ªùi gian th·ª±c th√†nh b√†i to√°n x·ª≠ l√Ω batch li√™n t·ª•c v·ªõi ƒë·ªô tr·ªÖ th·∫•p (near real-time) t·∫≠n d·ª•ng tr·ª±c ti·∫øp m√¥ h√¨nh v√† engine x·ª≠ l√Ω c·ªßa Spark Core.

### 4.3. Spark MLlib

Apache Spark MLlib (Machine Learning Library) l√† m·ªôt th∆∞ vi·ªán machine learning m√£ ngu·ªìn m·ªü v√† ph√¢n t√°n ƒë∆∞·ª£c t√≠ch h·ª£p ch·∫∑t ch·∫Ω v·ªõi Apache Spark.
MLlib cung c·∫•p m·ªôt lo·∫°t c√°c m√¥ h√¨nh machine learning v√† c√¥ng c·ª• cho vi·ªác x√¢y d·ª±ng, ƒë√†o t·∫°o v√† tri·ªÉn khai m√¥ h√¨nh h·ªçc m√°y tr√™n d·ªØ li·ªáu l·ªõn.

H√¨nh d∆∞·ªõi ƒë√¢y ƒë∆∞·ª£c l·∫•y t·ª´ cu·ªën s√°ch [Learning Spark: LIGHTNING-FAST DATA ANALYSIS](https://github.com/MinhHuuNguyen/data-engineer-lectures/blob/master/books/learning_spark_lightning_fast_big_data_analysis_holden_karau_andy_konwinski_patrick_wendell_matei_zaharia.pdf), m√¥ t·∫£ lu·ªìng ho·∫°t ƒë·ªông c∆° b·∫£n c·ªßa Machine Learning.

<img src="https://raw.githubusercontent.com/MinhHuuNguyen/data-engineer-lectures/refs/heads/master/3_hadoop_ecosystem/images/5-spark/machine_learning.jpeg" style="width: 800px;"/>

Spark MLlib t√≠ch h·ª£p ch·∫∑t ch·∫Ω v·ªõi Apache Spark, cho ph√©p s·ª≠ d·ª•ng ng√¥n ng·ªØ Scala, Java, Python ho·∫∑c R ƒë·ªÉ l√†m vi·ªác v·ªõi d·ªØ li·ªáu v√† th·ª±c hi·ªán machine learning tr√™n c·ª•m Spark.
ƒêi·ªÅu n√†y mang l·∫°i s·ª± m·∫°nh m·∫Ω v√† kh·∫£ nƒÉng m·ªü r·ªông c·ªßa Spark cho vi·ªác x·ª≠ l√Ω d·ªØ li·ªáu l·ªõn.

Spark MLlib cung c·∫•p m·ªôt lo·∫°t c√°c m√¥ h√¨nh machine learning kh√°c nhau bao g·ªìm c·∫£ machine learning c·ªï ƒëi·ªÉn v√† deep learning nh∆∞: classification, regression, clustering.
C√°c m√¥ h√¨nh n√†y ƒë√£ ƒë∆∞·ª£c t·ªëi ∆∞u h√≥a ƒë·ªÉ ho·∫°t ƒë·ªông tr√™n c·ª•m v√† x·ª≠ l√Ω d·ªØ li·ªáu ph√¢n t√°n.

Ngo√†i ra, Spark MLlib cung c·∫•p c√°c c√¥ng c·ª• v√† t√≠nh nƒÉng li√™n quan ƒë·∫øn machine learning nh∆∞ model evaluation, data pipeline, model pipeline.

### 4.4. Spark GraphX

Spark GraphX l√† m·ªôt th∆∞ vi·ªán m√£ ngu·ªìn m·ªü trong h·ªá sinh th√°i Apache Spark, ƒë∆∞·ª£c thi·∫øt k·∫ø ƒë·ªÉ x·ª≠ l√Ω v√† ph√¢n t√≠ch d·ªØ li·ªáu ƒë·ªì th·ªã.
Th∆∞ vi·ªán n√†y cung c·∫•p c√°c c·∫•u tr√∫c d·ªØ li·ªáu v√† c√°c thu·∫≠t to√°n ƒë·ªì th·ªã ƒë·ªÉ gi√∫p b·∫°n nghi√™n c·ª©u, ph√¢n t√≠ch m·∫°ng x√£ h·ªôi, x·ª≠ l√Ω d·ªØ li·ªáu ƒë·ªì th·ªã trong lƒ©nh v·ª±c khai th√°c d·ªØ li·ªáu v√† h·ªçc m√°y.

H√¨nh d∆∞·ªõi ƒë√¢y ƒë∆∞·ª£c l·∫•y t·ª´ cu·ªën s√°ch [Spark: The definitive Guide](https://github.com/MinhHuuNguyen/data-engineer-lectures/blob/master/books/spark_the_definitive_guide_bill_chambers_matei_zaharia.pdf), m√¥ t·∫£ m·ªôt ƒë·ªì th·ªã.

<img src="https://raw.githubusercontent.com/MinhHuuNguyen/data-engineer-lectures/refs/heads/master/3_hadoop_ecosystem/images/5-spark/graph.jpeg" style="width: 800px;"/>

Spark GraphX x·ª≠ l√Ω d·ªØ li·ªáu ƒë·ªì th·ªã, trong ƒë√≥ c√°c ƒë·ªânh v√† c·∫°nh c·ªßa ƒë·ªì th·ªã c√≥ th·ªÉ ƒë·∫°i di·ªán cho c√°c th·ª±c th·ªÉ v√† m·ªëi quan h·ªá gi·ªØa ch√∫ng.
ƒêi·ªÅu n√†y ph√π h·ª£p cho vi·ªác nghi√™n c·ª©u c√°c m·∫°ng x√£ h·ªôi, m·∫°ng l∆∞·ªõi, m·∫°ng th√¥ng tin, v√† nhi·ªÅu ·ª©ng d·ª•ng kh√°c.

Spark GraphX cung c·∫•p c·∫•u tr√∫c d·ªØ li·ªáu linh ho·∫°t ƒë·ªÉ bi·ªÉu di·ªÖn d·ªØ li·ªáu ƒë·ªì th·ªã, bao g·ªìm ƒë·ªì th·ªã h∆∞·ªõng v√† ƒë·ªì th·ªã kh√¥ng h∆∞·ªõng.
ƒêi·ªÅu n√†y cho ph√©p b·∫°n bi·ªÉu di·ªÖn m·ªôt lo·∫°t c√°c d·ªØ li·ªáu ƒë·ªì th·ªã ph·ª©c t·∫°p.

Spark GraphX cung c·∫•p m·ªôt lo·∫°t c√°c thu·∫≠t to√°n ƒë·ªì th·ªã nh∆∞ duy·ªát ƒë·ªì th·ªã (graph traversal), t√≠nh to√°n ƒë∆∞·ªùng ƒëi ng·∫Øn nh·∫•t (shortest path), t√¨m ki·∫øm ƒë·ªì th·ªã (graph search), t√≠nh to√°n b·∫≠c v√† thu·∫≠t to√°n ph√¢n c·ª•m (clustering algorithms) ƒë·ªÉ ph√¢n t√≠ch v√† kh√°m ph√° th√¥ng tin t·ª´ d·ªØ li·ªáu ƒë·ªì th·ªã.

### 4.5. C√°c API tr√™n c√°c ng√¥n ng·ªØ l·∫≠p tr√¨nh

C√°c API ƒëa ng√¥n ng·ªØ c·ªßa Spark cho ph√©p nhi·ªÅu nh√≥m ng∆∞·ªùi d√πng kh√°c nhau (k·ªπ s∆∞ h·ªá th·ªëng, data engineer, data scientist, nh√† ph√¢n t√≠ch) khai th√°c c√πng m·ªôt engine x·ª≠ l√Ω ph√¢n t√°n, v·ªõi m·ª©c ƒë·ªô tr·ª´u t∆∞·ª£ng v√† ƒë·ªô ph·ª©c t·∫°p ph√π h·ª£p.

| Ng√¥n ng·ªØ    | Vai tr√≤ ch√≠nh                                         | ƒê·∫∑c ƒëi·ªÉm n·ªïi b·∫≠t                                           | ƒê·ªëi t∆∞·ª£ng / Tr∆∞·ªùng h·ª£p s·ª≠ d·ª•ng                        |
| ----------- | ----------------------------------------------------- | ---------------------------------------------------------- | ----------------------------------------------------- |
| **Scala**   | API g·ªëc, ƒë·∫ßy ƒë·ªß nh·∫•t c·ªßa Spark                        | Hi·ªáu nƒÉng cao, h·ªó tr·ª£ to√†n b·ªô t√≠nh nƒÉng Spark              | Ph√°t tri·ªÉn h·ªá th·ªëng Spark l√µi, ·ª©ng d·ª•ng hi·ªáu nƒÉng cao |
| **Java**    | Cung c·∫•p kh·∫£ nƒÉng s·ª≠ d·ª•ng Spark trong m√¥i tr∆∞·ªùng Java | ·ªîn ƒë·ªãnh, t∆∞∆°ng th√≠ch t·ªët v·ªõi h·ªá sinh th√°i doanh nghi·ªáp     | ·ª®ng d·ª•ng doanh nghi·ªáp, h·ªá th·ªëng legacy                |
| **PySpark** | ƒê∆°n gi·∫£n h√≥a vi·ªác s·ª≠ d·ª•ng Spark cho ph√¢n t√≠ch d·ªØ li·ªáu | C√∫ ph√°p ng·∫Øn g·ªçn, d·ªÖ h·ªçc, ph·ªï bi·∫øn trong Data Science & ML | Ph√¢n t√≠ch d·ªØ li·ªáu v√† machine learning                 |
| **SparkR**  | H·ªó tr·ª£ ph√¢n t√≠ch th·ªëng k√™ tr√™n d·ªØ li·ªáu l·ªõn            | T√≠ch h·ª£p v·ªõi h·ªá sinh th√°i R                                | Ph√¢n t√≠ch th·ªëng k√™, nghi√™n c·ª©u                        |

#### So s√°nh gi·ªØa Spark Context v√† Spark Session

H√¨nh d∆∞·ªõi ƒë√¢y ƒë∆∞·ª£c l·∫•y t·ª´ cu·ªën s√°ch [Spark: The definitive Guide](https://github.com/MinhHuuNguyen/data-engineer-lectures/blob/master/books/spark_the_definitive_guide_bill_chambers_matei_zaharia.pdf), m√¥ t·∫£ c√°ch t·∫°o Spark Session trong Spark.

<img src="https://raw.githubusercontent.com/MinhHuuNguyen/data-engineer-lectures/refs/heads/master/3_hadoop_ecosystem/images/5-spark/spark_session.jpeg" style="width: 800px;"/>

Spark Context (SC) l√† ƒëi·ªÉm kh·ªüi ƒë·∫ßu ƒë·ªÉ t∆∞∆°ng t√°c v·ªõi Spark.
N√≥ ch·ªãu tr√°ch nhi·ªám thi·∫øt l·∫≠p k·∫øt n·ªëi v·ªõi c·ª•m Spark, qu·∫£n l√Ω t√†i nguy√™n v√† cung c·∫•p c√°c ph∆∞∆°ng th·ª©c ƒë·ªÉ t·∫°o RDD v√† th·ª±c thi c√°c t√°c v·ª• ph√¢n t√°n.
Spark Context l√† th√†nh ph·∫ßn c·ªët l√µi trong c√°c phi√™n b·∫£n Spark tr∆∞·ªõc 2.0.

Spark Session (SS) ƒë∆∞·ª£c gi·ªõi thi·ªáu t·ª´ Spark 2.0 nh∆∞ m·ªôt l·ªõp tr·ª´u t∆∞·ª£ng cao h∆°n, cung c·∫•p m·ªôt giao di·ªán th·ªëng nh·∫•t ƒë·ªÉ l√†m vi·ªác v·ªõi d·ªØ li·ªáu c√≥ c·∫•u tr√∫c v√† kh√¥ng c·∫•u tr√∫c, bao g·ªìm c·∫£ DataFrame v√† Dataset.
Spark Session ƒë∆°n gi·∫£n h√≥a vi·ªác c·∫•u h√¨nh v√† qu·∫£n l√Ω c√°c th√†nh ph·∫ßn Spark.

| Kh√≠a c·∫°nh         | SparkContext                                                | SparkSession                                                              |
| ----------------- | ----------------------------------------------------------- | ------------------------------------------------------------------------- |
| M·ª•c ƒë√≠ch          | K·∫øt n·ªëi cluster, thao t√°c RDD, c·∫•u h√¨nh executor            | Entry point th·ªëng nh·∫•t cho DataFrame/Dataset/SQL v√† truy c·∫≠p SparkContext |
| Ra ƒë·ªùi/phi√™n b·∫£n  | C√≥ t·ª´ ƒë·∫ßu (Spark core)                                      | T·ª´ Spark 2.0 tr·ªü ƒëi                                                       |
| Thao t√°c ch√≠nh    | RDD, low-level API, submit job                              | Read/Write (DataFrame), SQL, Catalog, c·∫•u h√¨nh session                    |
| T·∫°o/kh·ªüi t·∫°o      | `new SparkContext(conf)` (th·∫•p c·∫•p)                         | `SparkSession.builder().appName(...).getOrCreate()`                       |
| Khi n√™n d√πng      | Khi c·∫ßn thao t√°c RDD tr·ª±c ti·∫øp ho·∫∑c config cluster c·∫•p th·∫•p | H·∫ßu h·∫øt tr∆∞·ªùng h·ª£p hi·ªán ƒë·∫°i ‚Äî t·∫°o DataFrame, truy v·∫•n SQL, ML, Streaming  |

ƒê·ªëi v·ªõi ·ª©ng d·ª•ng hi·ªán ƒë·∫°i d√πng DataFrame/Dataset/SQL: d√πng SparkSession l√†m entry point.
N·∫øu c·∫ßn thao t√°c RDD th·∫•p c·∫•p ho·∫∑c c·∫•u h√¨nh chi ti·∫øt ·ªü m·ª©c core: v·∫´n c√≥ th·ªÉ s·ª≠ d·ª•ng spark.sparkContext.
